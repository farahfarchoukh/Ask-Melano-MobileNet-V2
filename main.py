# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mf6vCKd792AEcTBmUMZMc5Cb8tsw4upy

# Library Imports
"""

import os
import torch
import albumentations
from torchvision import models
import numpy as np
import pandas as pd
import torch.nn as nn
from sklearn import model_selection
from sklearn import metrics
from torch.utils.data import DataLoader
import cv2
from pathlib import Path

"""# Data Preparation and Exploration"""

from google.colab import drive
drive.mount('/content/drive')

!mkdir dataset

!unzip "/content/drive/MyDrive/Ask Melano Dataset/archive.zip" -d "/content/dataset"

import os
from pathlib import Path

# Define the dataset directory
dataset_dir = '/content/dataset'  # Replace with your dataset directory

# Subdirectories for train, data, and test
train_dir = os.path.join(dataset_dir, 'train')

# Function to create a DataFrame from the dataset directory
def create_dataframe(dataset_dir):
    image_paths = []
    targets = []
    for label in ['benign', 'malignant']:
        label_dir = os.path.join(dataset_dir, 'train', label)
        for img_file in os.listdir(label_dir):
            if img_file.endswith(('.jpg', '.jpeg', '.png')):
                image_paths.append(os.path.join(label_dir, img_file))
                targets.append(0 if label == 'benign' else 1)  # 0 for benign, 1 for malignant
    return pd.DataFrame({'image_name': image_paths, 'target': targets})

# Create DataFrame
df = create_dataframe(dataset_dir)

class ClassificationLoader(torch.utils.data.Dataset):
    def __init__(self, image_paths, targets, resize=None, augmentations=None):
        self.image_paths = image_paths
        self.targets = targets
        self.resize = resize
        self.augmentations = augmentations

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = cv2.imread(self.image_paths[idx])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB
        target = self.targets[idx]

        if self.resize:
            image = cv2.resize(image, self.resize)

        if self.augmentations:
            augmented = self.augmentations(image=image)
            image = augmented["image"]

        # Convert to (Channels, Height, Width) format and normalize
        image = np.transpose(image, (2, 0, 1)).astype(np.float32)
        return torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.float)

class MobileNetV2Wrapper(nn.Module):
    def __init__(self, pretrained=True):
        super(MobileNetV2Wrapper, self).__init__()
        self.model = models.mobilenet_v2(weights='DEFAULT' if pretrained else None)
        in_features = self.model.classifier[1].in_features
        self.model.classifier[1] = nn.Linear(in_features, 1)  # For binary classification

    def forward(self, image, targets):
        bs, _, _, _ = image.shape
        x = self.model.features(image)
        x = nn.functional.adaptive_avg_pool2d(x, 1)
        x = x.reshape(bs, -1)
        out = self.model.classifier(x)
        loss = nn.BCEWithLogitsLoss()(out, targets.reshape(-1, 1).type_as(out))
        return out, loss

def train(df, fold):
    df["kfold"] = -1
    df = df.sample(frac=1).reset_index(drop=True)
    y = df.target.values
    kf = model_selection.StratifiedKFold(n_splits=10)
    for fold_, (_, v_) in enumerate(kf.split(X=df, y=y)):
        df.loc[v_, "kfold"] = fold_

    model_path = "/content/drive/MyDrive/Ask Melano Dataset/model.pth"  # Adjust this path
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    epochs = 50
    train_bs = 32
    valid_bs = 16
    mean = (0.485, 0.456, 0.406)
    std = (0.229, 0.224, 0.225)

   # Split the data into training and validation sets
    df_train = df[df.kfold != fold].reset_index(drop=True)
    df_valid = df[df.kfold == fold].reset_index(drop=True)

    # If you don't have a validation set, create one from the training data
    if df_valid.empty:
        df_train, df_valid = model_selection.train_test_split(df_train, test_size=0.2, stratify=df_train['target'], random_state=42)

    # Data Augmentation
    train_aug = albumentations.Compose([
        albumentations.HorizontalFlip(),
        albumentations.VerticalFlip(),
        albumentations.RandomBrightnessContrast(),
        albumentations.Rotate(limit=30),
        albumentations.RandomCrop(height=224, width=224),
        albumentations.ElasticTransform(alpha=1.0, sigma=50.0, alpha_affine=50.0),
        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)
    ])

    valid_aug = albumentations.Compose([
        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)
    ])

    # Use the image paths directly from the DataFrame
    train_images = df_train.image_name.values.tolist()
    train_targets = df_train.target.values

    valid_images = df_valid.image_name.values.tolist()
    valid_targets = df_valid.target.values

    # Create datasets and data loaders
    train_dataset = ClassificationLoader(image_paths=train_images, targets=train_targets, augmentations=train_aug)
    train_loader = DataLoader(train_dataset, batch_size=train_bs, shuffle=True, num_workers=2)

    valid_dataset = ClassificationLoader(image_paths=valid_images, targets=valid_targets, augmentations=valid_aug)
    valid_loader = DataLoader(valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=2)

    # Initialize the model
    model = MobileNetV2Wrapper(pretrained=True)
    model.to(device)

    # Define optimizer with weight decay
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)

    # Initialize early stopping variables
    best_auc = 0
    patience = 5
    patience_counter = 0

    # Training loop
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for images, targets in train_loader:
            images, targets = images.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs, loss = model(images, targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        avg_loss = running_loss / len(train_loader)
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}")

        # Validation step
        model.eval()
        predictions = []
        valid_loss = 0.0
        with torch.no_grad():
            for images, targets in valid_loader:
                images, targets = images.to(device), targets.to(device)
                outputs, loss = model(images, targets)
                valid_loss += loss.item()
                predictions.append(outputs.sigmoid().cpu().numpy())  # Use sigmoid for binary classification

        avg_valid_loss = valid_loss / len(valid_loader)
        predictions = np.concatenate(predictions).ravel()
        auc = metrics.roc_auc_score(valid_targets, predictions)  # Calculate AUC

        # Print validation metrics
        print(f"Validation Loss: {avg_valid_loss:.4f}, AUC: {auc:.4f}")

        # Early stopping logic
        if auc > best_auc:
            best_auc = auc
            patience_counter = 0
            torch.save(model.state_dict(), model_path)  # Save the best model
            print(f"Model improved and saved to {model_path}")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print("Early stopping triggered.")
                break  # Exit the training loop if no improvement

        # Update learning rate based on validation loss
        scheduler.step(avg_valid_loss)

    print(f"Training completed. Best AUC: {best_auc:.4f}")
    print(f"Final model saved to {model_path}")

# Call the train function for a specific fold
if __name__ == "__main__":
    train(df, fold=0)  # You can change the fold number as needed
